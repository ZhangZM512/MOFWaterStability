{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4b5d9f-49c7-4405-b901-dd4b1858d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from pycm import ConfusionMatrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import balanced_accuracy_score as bal_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ed9d6-06c3-442d-9827-af823a4cd90a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9ffc5e-ec00-4e8f-ab4f-88921142f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .csv files\n",
    "\n",
    "path = r'Data/Train'\n",
    "filename = ['Descriptor_global_train.csv', 'Descriptor_atom_train.csv', 'Descriptor_bond_train.csv', 'Descriptor_metal_train.csv',\n",
    "            'Descriptor_linker_RDKit_train.csv', 'Descriptor_linker_MACCS_train.csv',\n",
    "            'Descriptor_RACs_train.csv', 'Target_train_1035.csv']\n",
    "\n",
    "load_data = []\n",
    "for f in filename:\n",
    "    if f != filename[-1]:\n",
    "        load_data.append(pd.read_csv(filepath_or_buffer=os.path.join(path,f),index_col=0).astype(float))\n",
    "    else:\n",
    "        load_data.append(pd.read_csv(filepath_or_buffer=os.path.join(path,f),index_col=0))\n",
    "\n",
    "load_data_content = {'Global':0 , 'Atom': 1, 'Bond': 2, 'Metal': 3, 'Linker_RDKit':4, 'Linker_MACCS':5,'RACs': 6, 'Target': 7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb9e9d-cfa4-44fb-aacf-9fd8391444bb",
   "metadata": {},
   "source": [
    "# Load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51d246a-4913-4ad4-b41b-3ade775ba496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier parameter\n",
    "\n",
    "ncvfold = 5\n",
    "scoring = 'f1_macro'\n",
    "param_grid = {'classifier1': {\"n_estimators\": [50,100,150,200], \"max_depth\": [15,25,35,45], \"max_features\": [2,3,4]},        # classifier 1\n",
    "              'classifier2': {\"n_estimators\": [50,200,400], \"max_depth\": [10,20,30], \"max_features\": [2,6,10,14]}}           # classifier 2\n",
    "\n",
    "# SMOTE parameter\n",
    "\n",
    "smote_grid = {'classifier1': SMOTE(sampling_strategy=\"auto\", random_state=0, k_neighbors=5),                                 # classifier 1\n",
    "              'classifier2': SMOTE(sampling_strategy=\"auto\", random_state=0, k_neighbors=5)}                                 # classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2162fc9-485f-4790-aaf7-6ac6f1cc3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_classification(select_data, select_data_content, select_descriptor, select_classifier):\n",
    "    \n",
    "    # (1) Build dataset for training\n",
    "    \n",
    "    all_index = [select_data[select_data_content[i]].index.tolist() for i in select_descriptor]\n",
    "    common_index = list(set.intersection(*[set(list_) for list_ in all_index]))\n",
    "    \n",
    "    output_train = pd.DataFrame()\n",
    "    for i in select_descriptor:\n",
    "        output_train = pd.concat([output_train,select_data[select_data_content[i]].loc[common_index,:]], axis=1, ignore_index=False)\n",
    "    output_train = pd.concat([output_train,select_data[-1].loc[common_index,'stability']], axis=1, ignore_index=False)\n",
    "    output_train.sort_index(key=lambda x: [int(i[3:]) for i in x], inplace=True)\n",
    "    \n",
    "    # (2) Classification strategy\n",
    "    \n",
    "    file = os.path.join(r'Data/Descriptor',select_classifier+'_descriptor.csv')\n",
    "    selXcols = [str(i) for i in list(pd.read_csv(file)['descriptor'])]\n",
    "    \n",
    "    if select_classifier == 'classifier1':\n",
    "        # Classifier 1: 3 / 2, 1, 0\n",
    "        output_train.loc[output_train['stability']==3,'stability']=-1\n",
    "        output_train.loc[output_train['stability']==2,'stability']=1\n",
    "        output_train.loc[output_train['stability']==1,'stability']=1\n",
    "        output_train.loc[output_train['stability']==0,'stability']=1\n",
    "\n",
    "    elif select_classifier == 'classifier2':\n",
    "        # Classfier 2: 3, 2 / 1, 0\n",
    "        output_train.loc[output_train['stability']==3,'stability']=-1\n",
    "        output_train.loc[output_train['stability']==2,'stability']=-1\n",
    "        output_train.loc[output_train['stability']==1,'stability']=1\n",
    "        output_train.loc[output_train['stability']==0,'stability']=1\n",
    "    \n",
    "    output_X = output_train.iloc[:,:-1]\n",
    "    output_Y = output_train.iloc[:,-1]\n",
    "    output_X = output_X[selXcols].copy()\n",
    "    output_X.sort_index(axis=1,inplace=True)\n",
    "    output_train = output_train[selXcols]\n",
    "\n",
    "    # (3) Classifier\n",
    "    \n",
    "    output_rf_clf = RandomForestClassifier(class_weight=\"balanced_subsample\", oob_score=True, random_state=0, n_jobs=-1)\n",
    "    output_CLF = GridSearchCV(output_rf_clf, cv = StratifiedKFold(n_splits=ncvfold, random_state=0, shuffle=True),\n",
    "                              param_grid = param_grid[select_classifier], scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    # (4) SMOTE\n",
    "\n",
    "    output_smote = smote_grid[select_classifier]\n",
    "    \n",
    "    print(select_classifier, ':')\n",
    "    print('Stable MOF: ', Counter(output_Y)[-1], ', Unstable MOF: ', Counter(output_Y)[1])\n",
    "    print('Feature space dimension:', output_X.shape)\n",
    "    return output_train, output_X, output_Y, output_CLF, output_smote\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cb42e9-73e3-45b8-8a76-55eb64803903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(input_seed, input_type, input_true, input_pred):\n",
    "    \n",
    "    output_metric_all = pd.DataFrame()\n",
    "    output_metric_all.loc[input_seed,input_type+'_ACC(w)'] = bal_score(y_true=input_true, y_pred=input_pred)\n",
    "    output_metric_all.loc[input_seed,input_type+'_ACC(u)'] = accuracy(y_true=input_true, y_pred=input_pred)\n",
    "    output_metric_all.loc[input_seed,input_type+'_PPV'] = precision_score(y_true=input_true, y_pred=input_pred, pos_label=-1)\n",
    "    output_metric_all.loc[input_seed,input_type+'_TPR'] = recall_score(y_true=input_true, y_pred=input_pred, pos_label=-1)\n",
    "    output_metric_all.loc[input_seed,input_type+'_F1'] = f1_score(y_true=input_true, y_pred=input_pred, pos_label=-1)\n",
    "    output_metric_all.loc[input_seed,input_type+'_AUC'] = roc_auc_score(input_true,input_pred)\n",
    "\n",
    "    output_metric_per_class = pd.DataFrame()\n",
    "    cm = ConfusionMatrix(actual_vector=input_true, predict_vector=input_pred)\n",
    "    output_metric_per_class.loc[input_seed,'AUC_S_'+input_type], output_metric_per_class.loc[input_seed,'AUC_U_'+input_type] = cm.AUC[-1], cm.AUC[1]\n",
    "    output_metric_per_class.loc[input_seed,'PPV_S_'+input_type], output_metric_per_class.loc[input_seed,'PPV_U_'+input_type] = cm.PPV[-1], cm.PPV[1]\n",
    "    output_metric_per_class.loc[input_seed,'TPR_S_'+input_type], output_metric_per_class.loc[input_seed,'TPR_U_'+input_type] = cm.TPR[-1], cm.TPR[1]\n",
    "    output_metric_per_class.loc[input_seed,'F1_S_'+input_type], output_metric_per_class.loc[input_seed,'F1_U_'+input_type] = cm.F1[-1], cm.F1[1] \n",
    "    \n",
    "    return output_metric_all, output_metric_per_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e842c51-c651-46ad-bed4-7a1806c3e759",
   "metadata": {},
   "source": [
    "# Train classifier: Ⅰ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231c06fc-63fa-4e1c-9cc3-e456ca9289a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier1 :\n",
      "Stable MOF:  678 , Unstable MOF:  357\n",
      "Feature space dimension: (1035, 75)\n"
     ]
    }
   ],
   "source": [
    "splits = [0.8]\n",
    "seeds = range(20)\n",
    "\n",
    "select_descriptor = ['Global','Metal','Linker_MACCS','Linker_RDKit']\n",
    "data_all, data_X, data_Y, CLF, smote = select_classification(select_data = load_data,\n",
    "                                                             select_data_content = load_data_content, \n",
    "                                                             select_descriptor=select_descriptor,\n",
    "                                                             select_classifier='classifier1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c838c2af-a77c-42c1-9395-6a159730d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:14<00:00,  6.72s/it]\n",
      "100%|██████████| 1/1 [02:14<00:00, 134.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean  median   min   max\n",
      "Test_ACC(u)  0.82    0.82  0.76  0.87\n",
      "Test_PPV     0.86    0.86  0.83  0.91\n",
      "Test_TPR     0.87    0.88  0.80  0.93\n",
      "Test_F1      0.86    0.86  0.81  0.90\n",
      "Test_AUC     0.80    0.79  0.74  0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in tqdm(splits):\n",
    "\n",
    "    metric_all = pd.DataFrame()\n",
    "    metric_per_class = pd.DataFrame()\n",
    "    \n",
    "    for rnseed in tqdm(seeds, position=0):\n",
    "\n",
    " \t\t# (1) Test-train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_X.values, data_Y.values, test_size=1-split,\n",
    "                                                            stratify=data_Y.values, random_state=rnseed)\n",
    "        scaler = StandardScaler()\n",
    "        scaler_save = scaler.fit(X_train)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "       \n",
    "        # (2) SMOTE\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "                \n",
    "        # (3) Train classifier\n",
    "        CLF.fit(X_train, y_train)\n",
    "        CLF_best = CLF.best_estimator_ \n",
    "        \n",
    " \t\t# (4) Evaluate classifier         \n",
    "        \n",
    " \t\t# (4.1) Training result\n",
    "        pred_train = CLF_best.predict(X_train)\n",
    "        m1_tr, m2_tr = metric(input_seed=rnseed, input_type='Train', input_true = y_train, input_pred = pred_train)\n",
    "\n",
    " \t\t# (4.2) Test result\n",
    "        pred_test = CLF_best.predict(X_test)\n",
    "        m1_tt, m2_tt = metric(input_seed=rnseed, input_type='Test', input_true = y_test, input_pred = pred_test)\n",
    "\n",
    "        metric_all = pd.concat([metric_all, pd.concat([m1_tr, m1_tt],axis=1)], axis=0)\n",
    "        metric_per_class = pd.concat([metric_per_class, pd.concat([m2_tr, m2_tt],axis=1)], axis=0)\n",
    "        \n",
    "        # (5) Save model\n",
    "        # if savemodel:        \n",
    "            # filename = r'Model/classifier1.pkl'\n",
    "            # pickle.dump(CLF_best, open(filename, 'wb'))\t\t\n",
    "            # filename = r'Model/classifier1_scaler.pkl'\n",
    "            # pickle.dump(scaler_save, open(filename, 'wb'))\n",
    "\n",
    "# Print metric\n",
    "metric_summary = pd.concat([metric_all.mean(), metric_all.median(), metric_all.min(), metric_all.max()],axis=1)\n",
    "metric_summary.columns=['mean','median','min','max']\n",
    "print(metric_summary.iloc[7:,].round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb52e6-9a92-4161-8a0d-235f5b5266a9",
   "metadata": {},
   "source": [
    "# Train classifier: Ⅱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1a61b6-6dc7-4b67-b25f-e06e560ee50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier2 :\n",
      "Stable MOF:  863 , Unstable MOF:  172\n",
      "Feature space dimension: (1035, 60)\n"
     ]
    }
   ],
   "source": [
    "splits = [0.8]\n",
    "seeds = range(20)\n",
    "\n",
    "select_descriptor = ['Global','Metal','Linker_MACCS','Linker_RDKit']\n",
    "data_all, data_X, data_Y, CLF, smote = select_classification(select_data = load_data,\n",
    "                                                             select_data_content = load_data_content, \n",
    "                                                             select_descriptor=select_descriptor,\n",
    "                                                             select_classifier='classifier2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf16bf3-9bbe-42dd-9ba8-3baee8eb2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:02<00:00, 12.11s/it]\n",
      "100%|██████████| 1/1 [04:02<00:00, 242.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean  median   min   max\n",
      "Test_ACC(u)  0.88    0.88  0.84  0.92\n",
      "Test_PPV     0.91    0.90  0.88  0.94\n",
      "Test_TPR     0.95    0.95  0.92  0.99\n",
      "Test_F1      0.93    0.93  0.91  0.95\n",
      "Test_AUC     0.73    0.72  0.63  0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in tqdm(splits):\n",
    "\n",
    "    metric_all = pd.DataFrame()\n",
    "    metric_per_class = pd.DataFrame()\n",
    "    \n",
    "    for rnseed in tqdm(seeds, position=0):\n",
    "\n",
    " \t\t# (1) Test-train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_X.values, data_Y.values, test_size=1-split,\n",
    "                                                            stratify=data_Y.values, random_state=rnseed)\n",
    "        scaler = StandardScaler()\n",
    "        scaler_save = scaler.fit(X_train)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "       \n",
    "        # (2) SMOTE\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "                \n",
    "        # (3) Train classifier\n",
    "        CLF.fit(X_train, y_train)\n",
    "        CLF_best = CLF.best_estimator_ \n",
    "        \n",
    " \t\t# (4) Evaluate classifier         \n",
    "        \n",
    " \t\t# (4.1) Training result\n",
    "        pred_train = CLF_best.predict(X_train)\n",
    "        m1_tr, m2_tr = metric(input_seed=rnseed, input_type='Train', input_true = y_train, input_pred = pred_train)\n",
    "\n",
    " \t\t# (4.2) Test result\n",
    "        pred_test = CLF_best.predict(X_test)\n",
    "        m1_tt, m2_tt = metric(input_seed=rnseed, input_type='Test', input_true = y_test, input_pred = pred_test)\n",
    "\n",
    "        metric_all = pd.concat([metric_all, pd.concat([m1_tr, m1_tt],axis=1)], axis=0)\n",
    "        metric_per_class = pd.concat([metric_per_class, pd.concat([m2_tr, m2_tt],axis=1)], axis=0)\n",
    "        \n",
    "        # (5) Save model\n",
    "        # if savemodel:        \n",
    "            # filename = r'Model/classifier1.pkl'\n",
    "            # pickle.dump(CLF_best, open(filename, 'wb'))\t\t\n",
    "            # filename = r'Model/classifier1_scaler.pkl'\n",
    "            # pickle.dump(scaler_save, open(filename, 'wb'))\n",
    "\n",
    "# Print metric\n",
    "metric_summary = pd.concat([metric_all.mean(), metric_all.median(), metric_all.min(), metric_all.max()],axis=1)\n",
    "metric_summary.columns=['mean','median','min','max']\n",
    "print(metric_summary.iloc[7:,].round(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
